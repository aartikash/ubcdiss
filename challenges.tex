\chapter{Challenges}
We face  the following challenges during the design of the technique. 
The  first challenge is choosing a mathematical abstraction technique that works best for our use case. 
The second challenge is mapping the \ac{DNN}  model to the abstraction. 
Finally, the last challenge is designing the \ac{DNN}  for our use case which is attack synthesis. 


\section{Selecting  the automated technique}
The first part is choosing a technique that allows the attacker to model a DNN and find the critical inputs through the modeling. 
There are multiple means of modeling the DNN to synthesize attacks some of which are using SMT solvers, symbolic execution and MILP.
Our goal is twofold: 
\begin{enumerate}
	\item Generality: \ac{APS} has an architecture that is despite being similar to our other evaluated systems is quite different from air control traffic management systems (\ac{ACAS-Xu} and \ac{HCAS}) as observed from Table 6.1.
	This is due to the difference in the application domain and the \ac{DNN} architecture design. 
	\ac{APS} is a medical system that consists of a standard feed-forward network with no exotic features such as normalization in the network unlike \ac{ACAS-Xu}
	Hence, we want an abstraction technique that supports such different architectures. 
	\item Scalability: \ac{APS} consists of 2 hidden layers with 50 neurons each which basically means that there are $2800$ ($50x5 + 50x50 + 50x1$) connections in total.
	\ac{ACAS-Xu} consists of 5 hidden layers with 50 neurons each which means the total connections are $10,500$. 
	Hence, we need a technique that is scalable to bigger systems. 
	
\end{enumerate}

 We show that \ac{MILP} fulfills these two criteria by providing us generality and scalability. 


\section{ Mapping  Mixed-Integer Linear Programming Model to Deep Neural Networks}

DNN architecture is quite complex and researchers have used experimental means to understand the security scenarios in the DNN. 
Their  mathematical structure contains multiple layers and the non-linearity introduced due to the activation functions within the network add another layer of complication for modeling in \ac{MILP}.
There are two main complications that arise here:
\begin{enumerate}
	\item Modeling each layer as a set of constraints to build a \ac{MILP} model.
	\ac{APS} has two layers as explained in Chapter 3 and has 50 neurons each. 
	We use that to 
	\item Non-linear terms are not allowed in \ac{MILP} modeling. Hence the big question here is how can we model the activation functions. 
\end{enumerate}

We formalize the \ac{DNN} to represent the entire network as a set of linear constraints. 
We tackle the non-linearity of activation functions by defining them as piece-wise linear which we demonstrate for one activation function ReLU.
We chose ReLU because are three evaluation systems have ReLU in their models. 

\section{Modeling cost function}
The goal of the cost function is to minimize or maximize the linear constraints that represents the \ac{DNN} architecture. 
However, our requirement is different in the traditional sense of using minimization and maximization which is usually used in terms of resource utilization. 
Based on our attack model we want to minimize the input perturbations and maximize the output deviations in a \ac{DNN}.
We do so to find the optimal solutions which we have defined in Section 2.5
There are two main problems that can arise based on our cost function modeling:
\begin{enumerate}
	\item There is a possibility that there are no solutions. 
	This happens if the \ac{MIP} is infeasible and we need to redefine our cost function. 
	\item If the \ac{MIP} is feasible, then there is a possibility that there is no optimal solution since there are infinitely many good cost function values. 
	This makes our solution space unbounded and can lead to state space explosions. 
\end{enumerate}

We demonstrate both the problems in our experimentation and show how we tackle the state space problem that can arise thereby scaling our approach for big sized systems. 
We use interval analysis which we elaborate in Chapter 5.


















