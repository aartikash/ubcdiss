\chapter{Conclusion}
\label{conclusion}

In this section we leverage our insights that can be used to design robust \ac{DNN}s. 
We discuss two main approaches that can help researchers or developers design error-free \ac{DNN}s. 
We also discuss some limitations in our approach.
Finally, we conclude and discuss some future work.


\section{Designing Robust DNNs}
From our experience in working with three different types of \ac{DNN} based CPS to attack the systems, we realized that there are two ways to construct or build robust \ac{DNN} based systems. 
The two things that help us in building our intuition were:
\begin{enumerate}
	\item Building and running the models on \ac{MILP} solvers helped us understand the power in terms of reasoning about \ac{DNN} based systems for observing non-obvious security properties such as ripples. 
	\item Attacking three practical systems helped  us come to a realization how to design robust \ac{DNN}  by adding layers of complexity to \ac{DNN}. 
\end{enumerate}


\subsection{Effects of normalization and attacks}
The biggest difference between \ac{APS} and \ac{ACAS-Xu} apart from the \ac{DNN} size was the robustness of the \ac{DNN}. 
\ac{APS} has a fully-connected feed-forward architecture, where the network takes the inputs and passes them through the hidden layers to compute the output. 
\ac{ACAS-Xu} is also a fully-connected \ac{DNN} however, it consists of one additional feature called normalization that we have defined in Chapter ~\ref{background}.
Due to the additional feature in \ac{HCAS} and \ac{ACAS-Xu} inducing small changes in the input will not lead to \ac{RFDIA}; this means that we have to try out more combinations in our model to find if the attack exists. 
This happens because the small perturbations during the \ac{FDIA} get masked due to the normalization layer; if we change the input value from $5$ to $10$ this will have little to no effect on the \ac{DNN} since the normalization layer normalizes a specific set of inputs to a value that lies between $0$ and $1$. 
This means that we have to perturb by values large enough such that after normalization the change is significant enough to generate ripples. 
We also observed that in a lot of cases despite large enough perturbation we were unable to generate \ac{RFDIA} in \ac{HCAS} and \ac{ACAS-Xu} as shown in Chapter ~\ref{evaluation}.
Intuitively due to the nature of the attacks based on the sizes of \ac{APS} and \ac{ACAS-Xu} we should have been able to generate significantly more \ac{RFDIA}; instead we observe that despite the bigger search space in \ac{HCAS} and \ac{ACAS-Xu} we found very few \ac{RFDIA} as compared to \ac{APS}. 
Hence, our conclusion based on this observation is that including features such as normalization can significantly help in designing 
\subsection{Effects of DNN size and attacks}
\ac{APS} was relatively a much smaller system as compared to \ac{ACAS-Xu} and \ac{HCAS}.
We observe that due to the smaller and much less complex nature of \ac{APS}, we are able to try out more combinations and hence are able to find more attacks. 
Every attack in \ac{APS} takes less than a minute to generate if it exists or tell us if it does not; \ac{HCAS} and \ac{ACAS-Xu} on the other hand 






APS had accompanying DNNs that kept\karthik{Duh ?} did a range check to ensure that the output prediction lies within certain bounds \karthik{Did you mean specified bounds ?}. 
This was easier to break as per our attack model as compared to ACAS Xu\karthik{Can we quantify easier? Also, by break, I guess you mean attack?}. 
In ACAS Xu, due to the normalization of the inputs, the perturbations had to be carefully designed since one input perturbation did not easily perturb the outputs easily \karthik{Too many easilys!}. 
We can also observe the percentage of successful attacks from Table II \karthik{Symbolic ref.?} in APS and ACAS Xu. \karthik{What did you observed about them?}
Hence, we believe that applying techniques while training and modeling DNN architecture can significantly help prevent \attack. \karthik{This is a vacuous statement. What techniques are these ? How does one go about designing such a DNN?}

\section{Debugging existing DNN using \tool}
Given there exists a system with DNN similar to that of APS without inbuilt mechanisms, we believe that our tool can help in debugging the DNN by constructing a comprehensive list of cost functions and running the model for different scenarios. This might not provide complete coverage but can certainly help in the falsification process. 
\karthik{So what's falsification here. Also, it seems like an overly restrictive statement to make about the similarity with APR. What's inbuilt mechanism here ?}

\section{ Limitations}

There are 2 limitations in our work.
First, we are assuming that the attacker has access\karthik{Read or write ? Be specific !} to the weights and the bias. However, in a more ideal attack scenario \karthik{for the attacker ?}, if we \karthik{Who's we?} can find a way to  attack the system without knowing the weights and bias of the system, that would be really interesting \karthik{Please avoid weasel words like interesting - make it clear what is of interest}. %Figuring out FDI attacks in that scenario would be challenging yet rewarding. 
Second, for bigger systems such as ACAS Xu, we observed that running all combinations was taking a lot of time (approx 13 hours), only to tell us that no attack exists \karthik{I suppose us is we as the researcher here. Also, is the time taken a function of the attacks or the network ?}. We think there is scope of improvement to provide speedups by applying clever heuristics to the model. \karthik{Perhaps give 1-2 examples of heuristics here.}


%The limitation of our work is that we do not evaluate the completeness of our approach. We show experimentally that our technique always provides us a solution if the model is properly modeled and if there are attacks possible. Otherwise, it returns an infeasible model.  Since the modeling of the network is represented as a set of well-defined equations it is always going to return a solution if it exists. If no solution exists then it will return the model is infeasible. 
%The interesting part of our approach is that we are not trying to verify but instead we are trying to find feasible FDI attacks for the system. 
\label{section:limitations}








We demonstrate \tool, which is based on generating \attack as an optimization problem using MILP \karthik{Does using MILP apply to optimization problem or to the tool ?}. We address the two main challenges in synthesizing \attack: 1) locating the critical inputs and, 2) finding the smallest perturbations for critical inputs to conduct \attack. To locate the critical inputs, we model a cost function and add $delta$ variable to the inputs and minimize the $delta$. This tells the attacker changing precisely which inputs will result in wrong output predictions. \karthik{I think you should mention changing the minimal set of inputs by the smallest possible amounts}
(This guides the attacker to minimize the inputs to mazimize\karthik{Spell check} the outputs 

%Insights
% - smaller systems easier to attack due to sizes
% - ACAS more robust due to the normalization layer that we discuss in Eva, and hence it is possible to make systems more robust
%- cost function affects the state explosion of the system. When we add a minimize delta, it takes longer because it has to find the smallest delta, whereas if we do not minimize the deltas and add general ranges, it returns the first feasible solution. 

Based on our experiments, we conclude that:

\begin{enumerate}
    \item The first well-known observation\karthik{If it's well known, then why do you say it is your finding?} is that it is easier (in terms of time) to find attacks on small-sized DNN based CPS. APS took less than a second for finding an attack whereas ACAS Xu took as high as 5 hours in some specific cases \karthik{For which cases}. 

\item We found fewer attacks in ACAS Xu as compared to APS indicating  that ACAS Xu is a more robustly designed network due to the existence of normalization that makes it difficult to generate ripples. Hence, it is possible to design robust DNN while designing the architectures. \karthik{The second sentence doesn't follow from the first in an obvious way}

\item Finally, we observe that the choice of the cost function affects the state explosion of the system. If there is a minimization function on the input perturbations, it takes much longer to compute and can also lead to explosions \karthik{I'm guessing you mean state-space, not the real kind !} in certain cases as compared to having no minimization function. \karthik{I think the better way to phrase this is comapring with other functions}
\end{enumerate}






\karthik{I think you should include discussion here and merge it with the future work below}
%Future work
Finally, we believe that there are many more extensions that can be done with \tool. First, it can be extended for multiple different application domains to find attacks. For eg. \karthik{'ve told you that you can't use e.g. this way} Autonomous Vehicles have multiple stacks of DNNs to compute the output and \tool can be utilized to find attacks in multiple DNNs. Second, one can try and model cost functions for an attack model different from ours and use our insights to generate attacks. Third, we observe that in some ACAS Xu attack scenarios, we were getting a time-out \karthik{I guess you mean that \tool timed out ?}, which tells us that there is the scope of improvement in the heuristics we have currently proposed for a speedup. \karthik{Not sure I understand how this follows - if you improved it, will  you be guaranteed there are no time-outs?}

\iffalse
We have addressed security as an optimization problem by modeling the Deep Neural Network as a Mixed Integer Linear model. This is the first step to automatically synthesize attacks called ripple attacks that on small perturbations to the input propagate further to cause output perturbations. 

We discussed the modeling details, designing attack specific cost functions \smi{change 'cost functions' to 'target inputs/perturbation bounds'; cost functions mean objective function which doesn't change for us}, finding critical inputs and finally finding the minimum perturbations for a successful attack that we call as a ripple attack. We show our evaluation on three systems of different sizes. Our biggest system size is (5,50,50,50,50,50,5). We model the cost functions such that even for big systems, our approach does not blow up \smi{we should chat and clarify the meaning of cost functions in this context}. We chose the three systems that are practical safety-critical systems that is an artificial pancreas system, and two aircraft collision avoidance networks.

For the medical system which is a considerably smaller system than our collision avoidance system, we are able to find the critical inputs and synthesize minimum perturbations in less than a second. For bigger system with more layers and number of neurons per layer, we are successfully able to synthesize attacks within a minute. 

We believe that using our technique to find similar attacks in systems such as self-driving cars that have multiple DNNs instead of one in their control system would be an interesting future work. As mentioned in the discussion section using our approach for tracing error propagation is another interesting use case. Finally, modeling application specific heuristics for systems such as surgical arm to synthesize attacks is another interesting topic for future research. 
\fi 
%\input{discussion}