\chapter{ReLUSyn}
In this section we explain the inner workings of our tool ReLUSyn. 
We show how fully connected feedforward \ac{DNN}s can be formulated as \ac{MILP} models. 
We use a generic representation and describe the modeling of cost functions that are used to generate \ac{RFDIA}.
We then show how this allows us to identify critical inputs and find the perturbations. 
We finally explain how we map this to real systems.
%Our approach is similar to that proposed by Fischetti et al. \cite{fischetti2017deep} where they propose a 0-1 MILP model for DNN modelling.
We also include a section on how \texttt{ReLU} (the non-linear activation function) might be modeled internally by MILP solvers based on work by Fischetti et al. \cite{fischetti2017deep}, where they propose a 0-1 MILP model for DNN modelling.
This section is included for completeness as the solver we use for our evaluation is able to handle the $\max$ function automatically.
\begin{figure}
	\centering
	\includegraphics[scale=0.1]{Images/Methodology}
	\caption[Methodology]{The rounded boxes depict the information provided by the users and the sharp corners is the information provided by us that integrates the first layer into the solver layer. \textcolor{red}{TODO: Add a red rectangle with dotted outline with 'input values' as text (in the blue box). This represents inputs that can be optionally provided by the attacker}}
	\label{fig:methodology}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{Images/DNNstructure}
	\caption[DNN structure]{DNN controller structure with two hidden layers K=1,2, two inputs x1 and x2 and one output y. This is an example of a fully connected network. \textcolor{red}{You should clarify the weight subscripts in my opinion.}}
	\label{fig:dnn-controller}
\end{figure}


\section{ReLUSyn: Overview}
\textcolor{red}{Why is 'bounds' in the blue rectangle? Aren't these the bounds on the input values (in which case, they would be part of the supplied DNN)?}

ReLUSyn is the technique that allows the attacker to generate \ac{RFDIA} attacks directly from the \ac{DNN} model. 
Our technique is shown in Figure 5.1.
The \ac{DNN} is made available from the system under attack; this DNN is passed directly into ReLUSyn. 
It automatically synthesizes a \ac{MILP} model from the \ac{DNN} model, which also contains the input value bounds. 
The attacker can specify a cost function if they possess the relevant domain-specific knowledge to make such a decision. The cost function determines the kind of attack to be launched on the system.
Everything inside the blue box is automatically synthesized.
The orange parts can be easily changed to extend the technique for different systems and applications in the future. 
The models along with the cost functions and bounds are passed through a MILP solver; the solver finds an optimal solution for the MILP model, and this optimal solution corresponds to an attack. If the solver determines the model is infeasible, then no attacks exist.
Each feasible solution of the model corresponds to a particular attack and the optimal solution corresponds to the preferred attack as specified by the user's cost function. We discuss the concept of using cost functions to launch specific attacks later in this chapter.

\section{DNN formalism}
We follow the formalism based on the general architecture that we explain in Chapter 2. 
The \ac{DNN} controller maps the inputs that are the $x1$ and $x2$ to the output $y$ as shown in  Figure 5.2.   
We now begin with the formal modeling of the \ac{DNN}.


%Formal modeling of a DNN for later use when explaining the modeling in MILP  
The architecture can be represented as a function F defined as $F: X \rightarrow Y$ where the inputs X are mapped to the output Y and are composed of multiple layers. 
We consider \ac{DNN} to be made up of $K + 1$ layers, numbered from 0 to K.
Layer 0 does not really exist since it is the input layer of the network.
The last layer K corresponds to the output of the \ac{DNN}.
Every individual layer in the \ac{DNN} $k$ $\epsilon$ $\{0,1,....,K\}$ is made by $n_k$ nodes or neurons in the network.
Each neuron has a bias associated with it. 
Every neuron from the previous layer is connected to every neuron in the next layer. 
The neurons are labeled starting from $1$ to $n_k$ in the network. 
We denote every neuron by $NODE(i,k)$ which corresponds to $ith$ node for the layer k. 

We denote the output vector of the layer $k$ as $F_k(x)$.
The output for every $NODE(i,k)$ denoted as $F_{ik}(k)$ \textcolor{red}{This should be $F_{ik}(x)$} where $i$ $\epsilon$ $\{0,1,....,n_k\}$ 

The output for layer 0 which is the \ac{DNN} input is represented as $F_k(0)$ \textcolor{red}{This should be $F_{0}(x)$}.
For every layer $k \geq 1$, the output vector is given by: 

\begin{equation}
\begin{aligned}
F_k(x) &= \upsigma(W^{k-1}x^{k-1} + b^{k-1}) \\
\end{aligned}
\end{equation}

where $\upsigma$ represents the activation function being used in the DNN under consideration.
There are several different activation functions which are all modelled differently such as \texttt{ReLU} ($f(x) = max {0,x}$) as shown in Figure 5.3 and the \texttt{logistic} activation function ($f(x)=1/(1+ exp(-e))$).
Our tool focuses on using \texttt{ReLU} since it is one of the most commonly used activation functions in \ac{DNN}s as Krizhevsky et al. \cite{10.1145/3065386} and it is easy to model as a piecewise linear function. 
Hence, our equation now looks something like where, for a vector $x$, \texttt{ReLU}($x$):= $\sum_{i=1}^{n} e_{i}\max(0, x_{i})$ (per layer).

\begin{equation}
\begin{aligned}
F_k(x) &= ReLU(W^{k-1}x^{k-1} + b^{k-1}) \\
\end{aligned}
\end{equation}

Since a network consists of multiple layers, the general \ac{DNN} representation looks like a composition function as shown below. 
\begin{equation}
	\begin{aligned}
	F(x) &= F_K \circ F_{K-1} \circ F_{K-2} ....... \circ F_1(x),    \\
	or \\
	F(x) &= F_K ( F_{K-1}( F_{K-2} .......  (F_1(x)))),    \\
	\end{aligned}
\end{equation}

This ends our \ac{DNN} formalism. We use this formalism in the next section to create a \ac{MILP} model. 

\section{MILP Model}
The \texttt{ReLU} activation function cannot be modelled directly by MILP solvers. This section presents an
equivalent formulation that is accepted by such solvers. The solver we use (\texttt{Gurobi}) handles this conversion
internally without exposing the user to the details. We have decided to include it here for the purpose of completeness.

To create a \ac{MILP} model, the essence lies in studying the basic scalar equation that describes the \ac{DNN} architecture.

\begin{equation}
\begin{aligned}
y &= ReLU(w^Ty + b) \\
\end{aligned}
\end{equation}

%This equation can be represented as a set of linear constraints in the \ac{MILP} model.
%To do so we use a $max$ operation that models the ReLU behavior.

We cannot apply the $f(X) = \max(0, x)$ operator directly because it is non-linear. Instead, we
can rewrite the equation given above as follows:

\begin{equation}
\begin{aligned}
w^Ty + b = x - s, x \geq 0, s \geq 0 \\
\end{aligned}
\end{equation}

The $y$ here represents the input from the previous layer and the $x$ represents the output of the current layer within the context of the DNN.
%We have elected to use different symbols for clarity..
The choice to use different symbols was made in the interest of clarity. The equation in this rewritten form is linear, and it does model
\texttt{ReLU} functionality (see Figure 5.3 for a visual representation) correctly as $x$ will always be non-negative. The problem with this formulation
is that it does not admit a unique solution. One way to account for this is to add indicator constraints of the form shown below. Modern MILP solvers can
handle these constraints directly.

%The reason we represent it as above is to first separate the equation from it's non-linear component such that we can convert it to it's linear component. 
%As the ReLU behavior is graphically explained in Figure 5.3 that the ReLU function can be broken in two parts which are the positive and the negative parts.  
%To implement such behavior we define a activation variable $ac$ that imposes the logical implications.

\begin{equation}
\begin{aligned}
ac = 1 \rightarrow x \leq 0  \\
ac = 0 \rightarrow s \leq 0  \\
ac \in \{0,1\} \\
\end{aligned}
\end{equation}

%This maps to the \ac{MILP} solvers and converts them into proper linear inequalities.
The $x \leq 0$ constraint in conjunction with $x \geq 0$ forces $x$ to zero. The other case forces $s$ to be zero.
This opens the door for a formulation that leads to unique solutions for $x$ and $s$ while enforcing the constraint $x \geq 0$.
The uniqueness may be achieved by adding a regularization term in the objective function that encourages most entries in $ac$ to be zero.
Extending this scalar example to the DNN case leads to a \ac{MILP} model of the form:
%The final \ac{MILP} model looks of the form
%\begin{equation}
%\begin{aligned}
%& \underset{}{\text{min/max}}
%& &  \sum_{k=0}^{K} \sum_{i=i}^{n_k}F_{jk}(x)   + \sum_{k=0}^{K} \sum_{i=i}^{n_k}F_{jk}(z)  \\
%\end{aligned}
%\end{equation}
%ReLU
%ReLU constraints
\begin{equation}
\begin{aligned}
& \sum_{j=0}^{n_k} w_{ij}^{k-1}x_{j}^{k-1} + b_i^{k-1} = x_i^k - s_i^k  \\
& & & x_i^k \geq 0, \\
& & & s_i^k \geq 0 \\
& & & ac_i^k  \in  \{0,1\} \\
& & & ac_i^k  =  1 \rightarrow  x_i^k \leq 0  \\
& & & ac_i^k =  0 \rightarrow s_i^k  \leq 0   \\
\end{aligned}
\end{equation}
Upper and lower bounds for range analysis
%Lower and upper bounds on the model
\begin{equation}
\begin{aligned}
& & & lb_i^k \leq x_i^k \leq ub_i^k, \\
& & &  \overline{lb_i^k} \leq s_i^k \leq \overline{up_i^k} \\
%& & & lb \leq z_i^k \leq up, \\
\end{aligned}
\end{equation}

%We have divided our \ac{MILP} model in three main parts.

%Equation 5.7 represents the cost functions that are to be minimized and maximized.
%These cost functions depend on different applications and requirements.  
%We will show in the next section how we model cost functions for \ac{RFDIA}
%attack synthesis.

Equations 5.7 represents the ReLU modeling for each layer in the network. 
We showed in Equation 5.6 how we can represent ReLU units as a set of linear constraints in \ac{MILP} solvers.
%We expand on it and apply it to all the layers in the modeling.

Equations 5.8 adds lower bounds ($lb$) and upper bounds ($up$) in the model. These will be 0 and $+\infty$ respectively except for the first input layer
where the bounds would depend on what is valid input for the DNN application.

Our MILP modelling applies the $f(x) = \max(0, x)$ operation directly to the output of layers because our MILP solver linearizes this internally when solving the model.
This section serves to illustrate how the solver could be handling this linearization internally. The next section describes how we build our model.


\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{Images/ReLUbreakdown}
	\caption{ReLU can be broken down into two linear units as shown in the figure for x $<$ 0 and x $\geq$ 0. This allows us to easily map the DNN equations in MILP models by breaking down the non-linearity inducing function.}
	\label{fig:relubreakdown}
\end{figure}

\section{Building the model}
\label{section:attacks}
%This section focuses on how we build the model using MILP and some background insights about DNN along with that. 
\tool comes with automated attack synthesizers for Artificial Pancreas System, Aircraft Collision Avoidance systems ACAS Xu and Horizontal CAS. %Writing a new attack synthesizer into \tool boils down to defining the attack model as a function that can be easily plugged in our framework.
As an example, we use a toy Artificial pancreas system (toyAPS) and then explain APS. A toyAPS as shown in Figure 5 consists of two sensor inputs that predict the amount of insulin as the output at some time $t$. 
\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{Images/ToyAPS}
	\caption[A ToyAPS]{A ToyAPS that takes in two inputs which we consider as the sensor values from the human. It predicts the amount of insulin to be injected at some time based on the sensor inputs.}
	\label{fig:toyaps}
\end{figure}


\begin{algorithm}
	%\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon    instead
	\KwIn{weight matrices, bias vectors, num\_layers, num\_neurons}
	\KwOut{DNN input, DNN output}
	Take the weight, bias, number of layers, and the number of neurons per layer. \\
	
	\textbf{Model}, \linebreak
	%\renewcommand{\labelenumi}{(\Roman{enumi})}
	%\begin{enumerate}[noitemsep,nolistsep]
	%\item
	(I) For every layer $k$ (with weight matrix $W_k$ and bias vector $b_k$), $output_k = W_k * input_k + b_k$
	\linebreak
	%\item 
	(II) Applying activation function to every layer's output,
	\linebreak
	Constraints: $ReLU\_output_k = max(0, output_k)$ (component-wise) \
	\linebreak
	The final layer's rectified output is the DNN output.
	
	\caption{Modeling neural network in MILP}
	\label{algo:b}
\end{algorithm}

The system can be represented as a MILP model through pseudocode in Algorithm 1. The model generated by this procedure is directly accepted by Gurobi (the solver we use for our experiments). %For our work we model our networks in Gurobi. 

An interesting point to note is that the DNN input is an output of Algorithm 1. This is because our procedure does not require an input to the DNN. This is because the resulting model can be solved to produce a valid input-output pair. Bounds can be enforced on the input variables by the user to ensure only
valid inputs are generated by the MILP solver. This is a positive consequence of using a constraint solving approach. The attacker does not need to have an input in hand when trying to compromise the system using \tool. It also means that we can enumerate many such input-output pairs by repeatedly solving the model
and adding constraints to exclude previously seen solutions.

\begin{align*}
Y &=  ReLU(Wx + b) ...... (4)
%Y &= ReLU(w_{11} x_1 + b_{11}  + w_{12} x_1 + b_{12} + w_{13} x_1 + b_{11}   )   \\
\end{align*}
The above equation represents the toyAPS. We convert the equations above into a MILP model as shown in Algorithm 1. Every layer is initially modeled as a linear equation, with the $\max$ operator being applied on top. This approach should work for other activation functions that are piecewise linear. Our approach will work for any representation of a piecewise linear function, as such functions can be modelled by MILP solvers using an approach similar to that described in the previous subsection. Our work specifically focuses on ReLU, as this is one of the more common activation functions.
\section{Modeling cost functions for attacks}
\label{section:costfunction}
%Why is modeling cost function important
Now that we have formulated the DNN as a MILP model, the next step is to add a cost or objective function to launch a specific kind of attack. This function allows the user to specify which inputs should be preferentially perturbed to generate a ripple.

Our toyAPS has two inputs $x_1$ and $x_2$ that map to an output $y$. The \attack causes minor changes in the inputs in a way that leads to a meaningful output change while avoiding detection through the input monitoring systems. These small changes cause the system to end up in a bad state eventually. In toyAPS, every small increase is a bad consequence of the system. Since the output determines the amount of insulin to be injected inside the body, small increases in the output can cause the diabetic patient harm \cite{ZHANG2019403} and can lead to cancer. 
Therefore in toyAPS the attacker's goal is to change the output to $y'$, where $y' = y + a$ with $a$ being some constant. %She needs to find the deviations in the input that would help her to change the outputs. 
However, the catch here is that the input perturbations should be very small such that the new input now provides the attacker with the output $y'$. The reason the attacker wants the input perturbations to be small is that there are accompanying neural networks that determine the upper and lower bounds for inputs and outputs at every stage. The reason for these accompanying networks is to ensure the patients' safety as explained in Section IV.%Hence, we have to minimize the perturbations. 
%This paragraph is explaining the subtlety of how we model our inputs for minimizing the perturbations. 
%We are hence minimizing the perturbations and not the inputs directly. Since minimizing the inputs directly will provide us with the smallest set of inputs that cause a deviation in the output. However, we want the smallest possible perturbations from the original image that change the output by the amount we want it to deviate. To find the smallest perturbations, we introduce a new variable delta for every input in the system. The new input is the addition of the original value and the minimized delta that ReLUSyn produces. 

Algorithm 1 describes the process of modeling a neural network in a MILP format. It does not mention a cost function since the function will be different for different systems depending on how the attacker wants to compromise said systems. We model the objective function by introducing a new variable that we denote $\Delta x$. This variable (which is actually a vector) represents the perturbations to the inputs in the synthesized attack. Equation (1) can therefore be rewritten as:

\begin{align}
Y &=  ReLU(W(x + \Delta x ) + b) ...... (5)
\end{align}

%The new cost modeling adds one layer of extension to our previous algorithm which is the objective function. Modeling any DNN can be done in the way presented in Algorithm 1 so long the activation function can be described as piecewise linear. 
%\smi{for MILP, this is only true if the activation function is piecewise linear}.
Algorithm 2 shows how to include the cost functions for different attacks as a part of the MILP model. The cost function can be changed based on the attack requirements.
\begin{algorithm}
	%\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon    instead
	\KwIn{input ($x$), weight matrices, bias vectors, num\_layers, num\_neurons}
	\KwOut{input\_delta ($\Delta x$), layer\_output, ReLU\_output,}
	Take the weight, bias, number of layers and number of neurons per layer. \\
	
	%\textbf{Model}, \linebreak
	%%\renewcommand{\labelenumi}{(\Roman{enumi})}
	%%\begin{enumerate}[noitemsep,nolistsep]
	%%\item
	%(I) For every  layer,  $expr = input * weight + bias$
	%\linebreak 
	%defining the linear expression
	%\linebreak
	%$layer\_output = expr$
	%\linebreak
	%%\item 
	%(II) Define the non-linear activation function 
	%\linebreak 
	%\qquad Constraint: $ReLU(x) = max (0,x)$
	%\linebreak
	%(III) Adding non-linearity to every layer,
	%\linebreak
	%Constraints: $ReLU\_output = ReLU(0, layer\_output)$\\, 
	%Repeat Step 2 until all layers are modeled 
	%\linebreak
	%$num\_layers < = 0$   $ \&\& $ 
	%$ num\_neurons < = 0 $.\\

	\textbf{Model}, \linebreak
	%\renewcommand{\labelenumi}{(\Roman{enumi})}
	%\begin{enumerate}[noitemsep,nolistsep]
	%\item
	(I) For the first layer $k = 0$ (with weight matrix $W_0$ and bias vector $b_0$), $output_0 = W_0 * (x + \Delta x) + b_k$
	\linebreak
	(II) For every subsequent layer $k \geq 1$ (with weight matrix $W_k$ and bias vector $b_k$), $output_k = W_k * input_k + b_k$
	\linebreak
	%\item 
	(III) Applying activation function to every layer's output,
	\linebreak
	Constraints: $ReLU\_output_k = max(0, output_k)$ (component-wise) \
	\linebreak
	(IV) Applying constraints to the DNN output to force the desired deviation
	\linebreak
	The final layer's rectified output is the DNN output.
	
	\textbf{Cost/Attack Function} \linebreak
	$\min |\Delta x|$
	%$Minimize $  $input\_delta$
	\caption{Modeling neural network in MILP with perturbation variables and a cost function}
	\label{algo:b}
\end{algorithm}

If there are two inputs as in our toyAPS, we can either try to minimize the delta values for both the inputs or only one of the inputs. The reason it is important to understand this is because, in general, within APS there are inputs that come from two different sensors as explained in the motivating example section. %The first sensor is attached to the back of the patient that captured the blood-glucose levels of the patient and the second input is from the insulin pump to get the measure of the insulin level in the pump.
The attacker might want to make changes to only one of the sensor readings. Hence, considering different scenarios, we can minimize the values depending on which inputs we are interested in targeting with an FDI attack. Our example cost function in Algorithm 2 minimizes the absolute values of the perturbations to both inputs.
The solver can minimize the cost function despite it not being linear by introducing an extra variable for each input and adding two additional constraints per input that bound the input's value using this newly introduced variable. This would essentially linearize the cost function.

\section{Finding critical inputs}
In our running example of APS, in reality, there are 74 inputs collected from two sensors every five minutes. The attacker's goal is to locate the critical inputs such that they can conduct FDI with minimal computational effort. To do so, as described in the previous two sections, the tool can be used to chose the index of inputs to be perturbed.
If we prefer all inputs equally, as we would be expected to in our initial attack, the solver implicitly indicates which inputs are more critical than others. The inputs with larger perturbations are clearly more important than those with smaller perturbations for changing the DNN's output.
We can relaunch attacks with those inputs specifically and further expanding the allowable bounds on the perturbations to narrow our search to the more promising sections of the search space.
We can specifically choose those inputs for conducting \attack.

%Depending on the attack model of the attacker, they can choose input(s) they are interested in finding the minimum perturbations for. We have implemented a framework that allows the users to pass the input index for inputs to be perturbed as a parameter. We will show this in the Evaluation section in more detail. 
\label{section:cost function}
\section{Synthesizing attacks}
The final part is synthesizing the inputs that can be used to conduct \attack without triggering any alarms in the system. We introduce the final constraints that put lower and upper bounds on the output of the networks. This is important for the optimization to return useful results. The reason the optimization approach wins here is that if we provide the proper constraints it gives us results in less than a second per attack. The state space is pruned appropriately by our technique through prudent decision variable bounds, and we experience state space explosions infrequently.
%\aarti{Should I add more here and also the algorithm for the synthesizing attack aspect?}              